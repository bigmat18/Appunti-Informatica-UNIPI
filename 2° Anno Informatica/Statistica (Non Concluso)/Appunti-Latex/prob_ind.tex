% !TeX spellcheck = it_IT
\newpage
\section{Probabilità e indipendenza}
Molte decisioni sono prese in condizioni di incertezza. Questo perché non è possibile conoscere con certezza il futuro in quanto qualsiasi affermazione possiamo fare potrebbe avverarsi come no. La teoria della probabilità nasce per quantificare questa incertezza, misurando la fiducia che un evento possa accadere.
\subsection{Spazi di probabilità}

\begin{definition}[Esperimento aleatorio]
	Un esperimento di cui non si conosce con certezza il risultato.
\end{definition}

\begin{definition}[Esito]
	Un ipotetico risultato di un esperimento aleatorio.
\end{definition}

\begin{definition}[Spazio campionario]
	Lo spazio di probabilità $\Omega$ è l'insieme di tutti gli esiti possibili $\omega$ dell'esperimento. 
\end{definition}

\begin{definition}[Evento]
	Un sottoinsieme dello spazio campionario che rappresenta un'affermazione che possiamo fare sull'esito dell'esperimento. Quando ha un solo elemento si dice \textbf{elementare}. $\Omega$ è un \textbf{evento certo} in quanto sottoinsieme improprio dello spazio campionario mentre $\emptyset$ è un \textbf{evento impossibile}.
\end{definition}

\noindent Consideriamo come esperimento il lancio di un dado:
\begin{equation*}
	A = \{\omega_2,\omega_4,\omega_6\} \qquad B=\{\omega_4,\omega_5,\omega_6\}
\end{equation*}
vediamo la corrispondenza tra le operazioni insiemistiche e logiche:
\begin{table}[h!]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		\textbf{Operazione insiemistica} & \textbf{Operazione logica} & \textbf{Esempio} \\
		\hline
		$A \cup B$ & Accade $A$ oppure $B$ & $A \cup B = \{\omega_2, \omega_4, \omega_5,\omega_6\}$ \\
		$A \cap B$ & Accadono $A$ e $B$ & $A \cap B = \{\omega_2, \omega_6\}$\\
		$A^c$ & Non accade $A$ & $A^c = \{\omega_1, \omega_3, \omega_5\}$\\
		$A \setminus B$ & Accade $A$ ma non $B$ & $A \setminus B = A \cap B^c = \{\omega_2\}$\\
		\hline
		\textbf{Relazione insiemistica} & \textbf{Relazione logica} & \textbf{Esempio}\\
		\hline
		$A \subseteq B$ & Se accade $A$ allora accade $B$ & $\{\omega_5\} \subset \{\omega_5, \omega_6\}$\\
		$A \cap B = \emptyset$ & Eventi \textbf{incompatibili} & $C$ esce un numero $<2$ e $B$\\
		\hline
	\end{tabular}
\end{table}

\subsection{Probabilità}
\begin{observation}
	Se due eventi sono incompatibili la probabilità che si realizzi uno qualsiasi dei due è la somma delle probabilità dei singoli eventi.
\end{observation}

\begin{definition}[Probabilità classica]
	Consideriamo uno spazio campionario $\Omega$ relativo ad un esperimento e $A\subseteq\Sigma$ un evento. La probabilità di $A$ è un valore $P(A) \in [0,1]$ che misura il grado di fiducia nell'evento.
	\begin{equation}
		P(A)=\frac{\#\text{casi favorevoli ad }A}{\#\text{casi possibili}} = \frac{\#A}{\#\Omega}
	\end{equation}
	Questa definizione è adatta solo se assumiamo che gli eventi elementari sono ugualmente probabili quindi solo per esperimenti su popolazione reale.
\end{definition}

\begin{definition}[Probabilità frequentista]
	Consideriamo un evento articolato in $n$ prove, nel corso del quale si verificano $k$ eventi elementari $\omega_1, \ldots, \omega_k$ incompatibili ma non equiprobabili.\\
	Supponiamo che $\omega_i$ si sia manifestato $n_i$ volte (frequenza assoluta), allora:
	\begin{equation}
		P(\omega_i) = \lim_{n \to \infty}\frac{n_i}{n}
	\end{equation}
	Questa definizione è adatta ai fenomeni fisici e biologici ma non sempre è possibile effettuare davvero tante prove (anche se oggi si simula). Inoltre non è detto che esista sempre il limite.
\end{definition}

\begin{definition}[Probabilità associativa]
	Dato uno spazio campionario $\Omega$ la probabilità è una funzione $P:\mathbb{P}\to \mathbb{R}$ tale che:
	\begin{itemize}
		\item $0 \leq P(A) \leq 1 \qquad \forall A \subseteq \Omega$
		\item $\mathbb{P}(\Omega)=1$
		\item se $(A_n)_{n=1,2,\ldots}$ è una successione di eventi incompatibili vale l'\textbf{addittività}
		\begin{equation}
			P\bigg(\bigcup_{n=1}^{+\infty}A_n\bigg) = \sum_{n=1}^{+\infty}P(A_n)
		\end{equation}
		e se la successione è infinita
		\begin{equation}
			P\bigg(\bigcup_{n=1}^{N}A_n\bigg) = \sum_{n=1}^{+N}P(A_n)
		\end{equation}
	\end{itemize}
\end{definition}

\begin{note}
	Si dice \textbf{trascurabile} un evento $A$ tale che $\mathbb{P}(A)=0$ e \textbf{quasi certo} un evento $A$ tale che $\mathbb{P}(A)=1$. 
\end{note}

\begin{definition}[Spazio di probabilità]
	La coppia $\Omega, P$ si dice spazio di probabilità.
\end{definition}

\begin{proposition}
	Proprietà della probabilità:
	\begin{itemize}
		\item $\mathbb{P}(A^c)=1-\mathbb{P}(A)$ e di conseguenza $\mathbb{P}(\emptyset)=0$
		\item $B \subseteq A \Longrightarrow \mathbb{P}(A\setminus B)=\mathbb{P}(A) - \mathbb{P}(B)$
		\item $\mathbb{P}(A\cup B)=\mathbb{P}(A)+\mathbb{P}(B)-\mathbb{P}(A \cap B)$
	\end{itemize}
\end{proposition}

\begin{proposition}[Limite di una successione di eventi]
	Data una successione di eventi $A_1, \ldots, A_n, \ldots$, questa può essere:
	\begin{itemize}
		\item \textbf{Crescente}: $A_n \subseteq A_{n+1}$ e quindi $A = \bigcup_{n=1}^{+\infty}A_n = \lim_{n \to  \infty A_n}$
		\item \textbf{Decrescente}: $A_n  \supseteq A_{n+1}$ e quindi $A = \bigcap_{n=1}^{+\infty}A_n = \lim_{n \to  \infty A_n}$
	\end{itemize}
	In entrambi i casi vale:
	\begin{equation}
		\mathbb{P}(A) = \lim_{n \to \infty}\mathbb{P}(A_n)
	\end{equation}
\end{proposition}

\subsection{Modello uniforme}
\begin{definition}[Modello uniforme]
	Definiamo il modello uniforme come lo spazio di probabilità$ (\Omega,P)$ tale che $\Omega$ è finito e ogni esito $\omega\in\Omega$ è equiprobabile, ovvero $P(\{\omega\})$ è la stessa $\forall \omega \in \Omega$.
\end{definition}

\subsubsection{Calcolo combinatorio}
Alcune formule notevoli:
\begin{itemize}
	\item \textbf{Sequenze ordinate con ripetizione} di $k$ numeri da $1$ a $n$: $n^k$
	\item  \textbf{Ordinamenti possibili} di $\{1, \ldots, n\}$: $n!$
	\item \textbf{Sequenze ordinate senza ripetizione} di $k$ numeri di $1, \ldots, n$
	\begin{equation*}
		\frac{n!}{(n-k)!} \quad\quad 0 \leq k \leq n
	\end{equation*}
	\item \textbf{Sottoinsiemi} di $\{1, \ldots, n\}$ formati da $k$ elementi
	\begin{equation*}
		\binom{n}{k} = \frac{n!}{k!(n-k)!} \quad\quad 0 \leq k \leq n
	\end{equation*}
\end{itemize}

\subsection{Probabilità condizionata}
Quando si è a conoscenza della realizzazione di un evento, cambia la valutazione di probabilità di ogni altro evento.
\begin{definition}[Probabilità condizionata]
	Dati due eventi $A, B$ con $B$ non trascurabile ($P(B) \neq 0$), la probabilità condizionata di $A$ rispetto a $B$ è
	\begin{equation}
		\mathbb{P}(A \vert B) = \frac{\mathbb{P}(A \cap B)}{\mathbb{P}(B)}
	\end{equation}
\end{definition}

\begin{observation}
	Fissato $B$ non trascurabile la funzione $A \mapsto P(A\vert B)$ è una probabilità. Non vale il contrario.
\end{observation}

\begin{proposition}[Regola dei prodotti]
	Se l'intersezione di eventi $A_1 \cap \ldots \cap A_{n-1}$ non è trascurabile vale
	\begin{equation}
		\mathbb{P}(A_1 \cap \ldots \cap A_n) = \mathbb{P} (A_1) \cdot \mathbb{P}(A_2 \vert A_1) \cdot \ldots \cdot \mathbb{P}(A_n \vert A_1 \cap \ldots \cap A_{n-1})
	\end{equation}
\end{proposition}

\begin{demostration}
	Vediamo la dimostrazione della regola dei prodotti nel caso con $A$ e $B$. Abbiamo:
	\begin{equation*}
		P(A\vert B)=\frac{P(A \cap B)}{P(B)} \qquad \qquad P(B\vert A)=\frac{P(B\cap A)}{P(A)}
	\end{equation*}
	Però, sapendo che $P(A\cap B) = P(B \cap A) $ possiamo dire che
	\begin{equation*}
		P(A \vert B) \cdot P(B) = P(A\cap B) = P(B\cap A) = P(B \vert A) \cdot P(A)
	\end{equation*}
\end{demostration}

\begin{definition}[Partizione]
	Una partizione di $\Omega$ è una collezione di $n$ eventi $B_1, \ldots, B_n$ a due a due disgiunti tali che
	\begin{equation}
		B_1 \cup \ldots \cup B_n = \Omega
	\end{equation}
\end{definition}
\begin{definition}[Sistema di alternative]
	È una partizione di $\Omega$ in eventi non trascurabili.
\end{definition}

\begin{theorem}[Formula della probabilità o della fattorizzazione]
	Dato $B_1, \ldots, B_n$ un sistema di alternative, per un qualunque evento $A$ vale
	\begin{equation}
		\mathbb{P}(A) = \sum_{i=1}^{n} \mathbb{P}(A \vert B_i) \mathbb{P}(B_i)
	\end{equation}
\end{theorem}

\begin{definition}[Formula di Bayes]
	Dati $A$ e $B$ due eventi non trascurabili vale
	\begin{equation}
		\mathbb{P}(B \vert A) = \frac{\mathbb{P}(A \vert B)\mathbb{P}(B)}{\mathbb{P}(A)}
	\end{equation}
\end{definition}
\begin{definition}[Formula di Bayes - Alternative]
	Dati $A$ un evento e $B_1, \ldots, B_n$ un sistema di alternative vale
	\begin{equation}
		\mathbb{P}(B_i \vert A) = \frac{\mathbb{P}(A \vert B_i)\mathbb{P}(B_i)}{\sum_{j=1}^{n} \mathbb{P}(A B_j)\mathbb{P}(B_j)}
	\end{equation}
\end{definition}

\subsection{Indipendenza}
L'idea è che la conoscenza che si è realizzato un certo evento non modifica la valutazione di probabilità di un altro evento.
\begin{definition}
	Dati $n$ eventi $A_1, \ldots, A_n$, questi sono indipendenti se per ogni $k$ con $2 \leq k \leq n$ e per ogni scelta di interi $1 \leq i_1 < i_2< \ldots < i_k \leq n$ vale
	\begin{equation}
		\mathbb{P}(A_{i_1} \cap \ldots \cap A_{i_k}) = \mathbb{P}(A_{i_1}) \cdot  \ldots \cdot \mathbb{P}(A_{i_k})
	\end{equation}
\end{definition}

\begin{observation}[Complessità]
	Il numero di uguaglianze da verificare per $n$ eventi è
	\begin{equation*}
		2^n -n -1
	\end{equation*}
\end{observation}

\begin{proposition}[Spazi prodotto]
	Si consideri
	\begin{equation*}
		\Omega = \{a=(a_1, \ldots, a_n) \vert a_i = 0,1\} = \{0, 1\}^n
	\end{equation*}
	su cui definiamo per ogni $a$ la probabilità
	\begin{equation*}
		\mathbb{P}(\{a\}) = p^ {\# \{i:a_i = 1\}} (a-p)^{\# \{i:a_i = 0\}} = p^{\sum_{i=1}^{n}a_i}(a-p)^{n-\sum_{i=1}^{n} a_i}
	\end{equation*}
	E gli eventi
	\begin{equation*}
		A_i = \{a \in \Omega: a_i = 1\} \quad\quad i = 1, \ldots, n
	\end{equation*}
	sono indipendenti tra di loro, così come i complementari $A^c_i$.
\end{proposition}

\begin{observation}
	Due eventi possono essere indipendenti anche in presenza di una relazione causale. Viceversa due eventi possono essere dipendenti anche in assenza di una relazione causale.
\end{observation}

\subsection{Entropia di Shannon}
Una misura di probabilità può essere uno strumento per quantificare l'informazione.
\begin{definition}[Entropia]
	Data una misura di probabilità discreta $\mathbb{P}$ su $\Omega = \{x_1, \ldots, x_n\}$, con $p_i = \mathbb{P}(\{x_i\})$, la sua entropia è data dalla funzione
	\begin{equation}
		H^{(n)}(p_1, \ldots, p_n) = - \sum_{i=1}^{n}p_i \log(p_i)
	\end{equation}
\end{definition}

\begin{proposition}
	Valgono:
	\begin{enumerate}
		\item La funzione dell'entropia è \textbf{simmetrica}: scambiando $p_i$ e $p_j$ non cambia
		\item $H^{(n)}(1, 0,\ldots, 0) =0$
		\item È coerente tra $n$ diversi: $H^{(n)}(p_1=0, p_2, \ldots, p_n) = H^{(n-1)}(p_2, \ldots, p_n)$
		\item $h^{(n)}(p_1, \ldots, p_n) \leq H^{(n)}\big(\frac{1}{n}, \ldots, \frac{1}{n}\big)$, ovvero la massima entropia è data dalla distribuzione uniforme di probabilità
		\item Data una probabilità su $n \times m$ oggetti $\Omega = \{x_{11}, \ldots, x_{ij}, \ldots, x{nm}\}$ con $\mathbb{P}({x_ij})=q_{ij}$, considerando gli eventi $A_i = \{x_{i,1}, \ldots, x_{i,m}\}$ con $\mathbb{P}(A_i)=p_1$ vale
		\begin{equation*}
			H^{nm}(q_{11}, \ldots, q_{ij}, \ldots, q_{nm}) = H^{(n)}(p_1, \ldots, p_n) + \sum_{i=1}^{n}p_i H^{(m)}\bigg(\frac{q_{i1}}{p_1}, \ldots, \frac{q_{im}}{p_i}\bigg)
		\end{equation*}
		ovvero l'entropia è data da quella relative al sistema di alternative $A_i$ più la media pesata delle entropie relative nei blocchi $A_i$.
	\end{enumerate}
\end{proposition}

\begin{theorem}[Shannon]
	Una funzione che soddisfa le 5 proprietà ha la forma
	\begin{equation}
		cH^{(n)} \quad\quad c>0
	\end{equation}
\end{theorem}

\subsection{Densità di probabilità}
\begin{definition}[Densità di probabilità]
	Una funzione non negativa $f: \mathbb{R} \to [0, + \infty]$, integrabile e tale che 
	\begin{equation*}
		\int_{-\infty}^{+\infty}f(x)dx = 1
	\end{equation*}
	La sua probabilità è 
	\begin{equation}
		\mathbb{P}(A) = \int_{A}f(x)dx \quad\quad A \subseteq \Omega
	\end{equation}
\end{definition}

\begin{observation}
	La probabilità di ogni singolo punto è nulla
	\begin{equation}
		\mathbb{P}(\{t\})=\int_{\{t\}}f(x)dx=0
	\end{equation} e in generale
	\begin{equation}
		\mathbb{P}(A) = 0 \quad\quad \forall A \subset \mathbb{R}
	\end{equation}
\end{observation}